# Default values for qtest-manager-chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

reloader:
  enabled: false

rollouts:
  enabled: false

deployments:
  enabled: true

liquibase:
  annotations:
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation, hook-succeeded
    # argocd.argoproj.io/hook: PreSync
    # argocd.argoproj.io/hook-delete-policy: HookSucceeded, BeforeHookCreation
  configmapAnnotations:
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-weight: "-5"
    helm.sh/hook-delete-policy: before-hook-creation, hook-succeeded
    # argocd.argoproj.io/hook: PreSync
    # argocd.argoproj.io/sync-wave: "-5"
    # argocd.argoproj.io/hook-delete-policy: HookSucceeded, BeforeHookCreation

annotations: {}

podAnnotations: {}

env: []

image:
  repository: 242129367204.dkr.ecr.us-east-1.amazonaws.com/qtestmgr
  liquibase: 242129367204.dkr.ecr.us-east-1.amazonaws.com/liquibase
  pullPolicy: IfNotPresent
  tag: "10.5.1-06cc314"
  liquibasetag: "10.5.1-06cc314"
  liquibasepullpolicy: IfNotPresent

imageCredentials:
  enabled: false
  name: ""
  registry: ""
  username: ""
  password: ""
  email: ""

secrets:
  enabled: false
  # existingConfigs: ""
  # existingImageCredentials: ""
serviceAccount:
  create: true
  name:
  annotations: {}
  automountsatoken: false

service:
  type: LoadBalancer
  annotations: {}
  port: 8080
  targetPort: 8080
  targetSigSciPort: 8081
  servicename: mgr-service
  # servicePortHttp: 80
  # servicePortHttps: 443
  # servicePortHttpName: http
  # servicePortHttpsName: https

SigSci:
  enabled: false
  # existingSecret: "sigsci-secret"
  accesskeyid: ""
  secretaccesskey: ""

qTestManager:
  client:
    jdbc:
      postgresUrl: "jdbc:postgresql://postgres.local:5432/qtest"
      postgresUserName: "qtest"
      postgresPassword: ""
      postgresReadOnlyUrl: "jdbc:postgresql://postgres_replica.local:5432/qtest"
      postgresReadOnlyUserName: "qtest"
      postgresReadOnlyPassword: ""
  elasticSearch:
    init: false
    disable: true
    scheme: http
    host: elasticsearch.local
    port: 9200
    permittedClients: ""
  attachmentFolderPath: /usr/local/tomcat/temp
  blobStorage:
    region: us-east-1
    sharedBucket: "qtest"
  s3:
    folder: qtest/manager
    scanUrl: https://clamav-13.container-dev.qtestdev.com
  serverAppUseSecureCookie: true
  serverAppSSLRequired: false
  preUrl: http://nephele.qtest.local
  preUrlHttps: https://nephele.qtest.local
  qasymphonyUrlPostfix: .qtest.local
  qasDirectoryAddress: http://qtest-auth.local/tc-auth
  kafka:
    enable: false
    bootstrapAddress: "kafka-broker.local:9092"
    schemaRegistryUrl: "https://schema-registry.local"
  preSessionUrl: "http://sessions.local"
  pulseUrlBase: "http://pulse.local"
  insightsUrl: "http://insights.local"
  launchUrlBase: "http://launch.local"
  notification:
    urlExternal: "http://notification.qtest.local"
    # com.qasymphony.qtest.event.service.ToscaQueueEventPublisher#maxDequeue
    ToscaQueueEventProcessingServiceMaxDequeue: 0
    springProfilesActive: postgres
    actionTaskExecutorPoolSize: 0
  qTest:
    serverMapUrl: "http://qtest.local/public/jira-widget/server-map"
    instance: US
    ODPrivate: false
  tdmSettingUrl: "http://parameters-service"
  mail:
    host: "smtp.local"
    port: 465
    userName: "qtest"
    password: ""
    supportEmailAddress: supports@tricentis.com
  integration:
    jira:
      testConnectionLegacyEndpointClients: ""

testconductor:
  environment:
    isOnPremise: false
    od:
      ui: ui.production
      api: api.production
      poller: poller.production
      notification: notification.production
    op:
      ui: ui.onpremise
      api: api.onpremise
      poller: poller.onpremise
      notification: notification.onpremise

ingress:
  enabled: true
  ingressClassName: ""
  annotations:
    kubernetes.io/ingress.class: ""
  canary:
    annotationPrefix: ""
    annotations: {}
      # canary-by-header: []
      # canary-by-header-pattern: []
  labels: {}
  hosts: []
  paths:
    - /
  extraPaths:
    []
    # - path: /*
    #   backend:
    #     serviceName: ssl-redirect
    #     servicePort: use-annotation
  tls:
    []
    # - secretName: qtest-example-tls
    #   hosts:
    #     - foo.qtest.com
  https: false

# CD Pipeline use only
chaos:
  enabled: false
workflow:
  enabled: false
  annotations: {}
  adminModeNamespace: litmus
  serviceAccountName: ""
  podGC: OnWorkflowSuccess
  secret: ""
  revision: ""
  postman:
    repo: ""
    image: public.ecr.aws/b8y7a2x6/argo-agent:ubuntu.2

# Metrics for nginx ingress controller for application and cluster analysis
metrics:
  enabled: false
  prometheus:
    address: ""
    query: ""

persistence:
  enabled: true
  annotations: {}

  ## Specify an existing volume claim instead of creating a new one.
  ## When using this option all following options like storageClass, accessMode and size are ignored.
  # existingClaim:

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ## set, choosing the default provisioner.  (gp2 on AWS, standard on
  ## GKE, AWS & OpenStack)
  ##
  storageClass:
  accessMode: ReadWriteMany
  size: 10Gi

  ## Specify extra volumes. Refer to ".spec.volumes" specification : https://kubernetes.io/fr/docs/concepts/storage/volumes/
  volumes: []
  ## Specify extra mounts. Refer to ".spec.containers.volumeMounts" specification : https://kubernetes.io/fr/docs/concepts/storage/volumes/
  mounts: []

# VPA values
vpaAutoscaling:
  enabled: false
  updatePolicy:
    updateMode: "Off"

# HPA values
autoscaling:
  enabled: true
  minReplicas:
    ui: 1
    api: 1
    notification: 1
    poller: 1
    default: 1
  maxReplicas:
    ui: 3
    api: 3
    notification: 3
    poller: 1
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 70
  healthApiPath: /health-checker

resourceQuota:
  enabled: true
  hard:
    limits.cpu: '80'
    limits.memory: 400Gi
    requests.cpu: '64'
    requests.memory: 160Gi
    pods: '25'
    persistentvolumeclaims: '50'
    requests.storage: 500Gi
limitRange:
  enabled: true
  limits:
    - max:
        cpu: '2'
        memory: 16Gi
      default:
        cpu: '2'
        memory: 16Gi
      defaultRequest:
        cpu: '2'
        memory: 4Gi
      type: Container

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

## Readiness, liveness and startup probes
livenessProbe:
  httpGet:
    path: /health-checker
    port: 8080
  initialDelaySeconds: 70
  periodSeconds: 30
  failureThreshold: 20
readinessProbe:
  httpGet:
    path: /health-checker
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 30
  failureThreshold: 20
startupProbe:
  httpGet:
    path: /health-checker
    port: 8080
  periodSeconds: 30
  failureThreshold: 20

nodeSelector: {}

tolerations: []

affinity: {}
